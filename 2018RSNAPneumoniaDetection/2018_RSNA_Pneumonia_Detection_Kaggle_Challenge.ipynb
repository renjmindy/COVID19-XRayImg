{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018 RSNA Pneumonia Detection Kaggle Challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKY68Gvw6KIv"
      },
      "source": [
        "1 Install and import the requirements:\n",
        "\n",
        "install dependencies not included by Colab\n",
        "\n",
        "use pip3 to ensure compatibility w/ Google Deep Learning Images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT9dyCn32b93",
        "outputId": "b5fac0dd-31ad-4b63-a6ac-80017a1791f9"
      },
      "source": [
        "!pip3 install -q pydicom"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9MB 6.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgUiMZfn5_jk"
      },
      "source": [
        "!pip3 install -q tqdm "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBycVjL6aaC"
      },
      "source": [
        "!pip3 install -q imgaug"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvCVdnB5623x"
      },
      "source": [
        "import os \n",
        "import sys\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pydicom\n",
        "from imgaug import augmenters as iaa\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import glob\n",
        "from google.colab import files"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXd1d9479LNQ",
        "outputId": "61007a28-f220-4535-bc8c-110d7ba3c692"
      },
      "source": [
        "# Install Kaggle API to download competition data\n",
        "# https://www.kaggle.com/general/74235\n",
        "\n",
        "!pip3 install -q kaggle\n",
        "\n",
        "!pip3 install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=848a82dd1a6af9c57ce17621c2ce471c9b7b70a7012dd682881be596b2fa6434\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yuehq3rYJOFt",
        "outputId": "70e0754a-7bdd-4e65-acb1-102747935c04"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'kaggle*.json': No such file or directory\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyO1yzMeaL7J"
      },
      "source": [
        "#!rm kaggle*.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "cAMv57Xr8_b3",
        "outputId": "a44fe103-fc46-49c4-827d-70b388b778b8"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d59a8a0f-f705-47e3-86bd-8e42f7194fd2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d59a8a0f-f705-47e3-86bd-8e42f7194fd2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"mindyjen\",\"key\":\"d93d23dee9c18e05d21517d0fadb8efa\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1NvuWVf9Aiz",
        "outputId": "5aa28421-c0ec-44b4-82ab-0c951b71edd1"
      },
      "source": [
        "#! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets list"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                                         title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              229KB  2021-05-19 19:53:33           5559        510  1.0              \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           3056        271  0.9375           \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            369         41  1.0              \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   1GB  2021-02-18 10:08:27           1835        148  1.0              \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           1079         94  1.0              \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52            764         35  1.0              \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            624         94  0.9375           \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            482         23  0.9411765        \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00            572         46  0.75             \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            137         34  1.0              \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            293         17  0.75             \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            115         42  1.0              \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26             53         20  0.6875           \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54             60         19  0.8125           \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51             72         16  0.875            \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40             72         14  0.6875           \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         139990       3957  0.7941176        \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         136510       3065  0.7941176        \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          18125        716  0.8235294        \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          22954        558  0.7058824        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U39qMhXk9tSi"
      },
      "source": [
        "2 Download the dataset:\n",
        "\n",
        "The competition has two stages, so for the current stage (stage 1) the files are:\n",
        "\n",
        "Train images: “stage_1_train_images.zip”\n",
        "\n",
        "Test images:”stage_1_test_images.zip”\n",
        "\n",
        "Training data: “stage_1_train_labels.csv”\n",
        "\n",
        "Sample submission file: “stage_1_sample_submission.csv”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDWNZQ1dzYKp"
      },
      "source": [
        "3 You must accept the user agreement on the competition website:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSMlx3tX9kdf"
      },
      "source": [
        "# enter your Kaggle credentials here\n",
        "os.environ['KAGGLE_USERNAME']=\"mindyjen\"\n",
        "os.environ['KAGGLE_KEY']=\"d93d23dee9c18e05d21517d0fadb8efa\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOYRmE3ArF2x"
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath('./lesson3-data')\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, 'logs')\n",
        "if not os.path.exists(ROOT_DIR):\n",
        "    os.makedirs(ROOT_DIR)\n",
        "os.chdir(ROOT_DIR)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THc1OQQp7AGt",
        "outputId": "06b0d877-f84c-4acb-d8f4-c971cd08dadf"
      },
      "source": [
        "# If you are unable to download the competition dataset, check to see if you have \n",
        "# accepted the user agreement on the competition website. \n",
        "!kaggle competitions download -c rsna-pneumonia-detection-challenge"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading rsna-pneumonia-detection-challenge.zip to /content/lesson3-data\n",
            "100% 3.66G/3.66G [00:45<00:00, 54.2MB/s]\n",
            "100% 3.66G/3.66G [00:45<00:00, 87.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LaDNPT7Zqwc"
      },
      "source": [
        "# unzipping takes a few minutes\n",
        "!unzip -q -o rsna-pneumonia-detection-challenge.zip"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tl1lz_ka-Cm",
        "outputId": "2aaac026-59e3-4e56-c6f0-ceda8cbc1ad5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'GCP Credits Request Link - RSNA.txt'\t  stage_2_test_images\n",
            " rsna-pneumonia-detection-challenge.zip   stage_2_train_images\n",
            " stage_2_detailed_class_info.csv\t  stage_2_train_labels.csv\n",
            " stage_2_sample_submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUcMNdti7SXV"
      },
      "source": [
        "#!ls stage_2_train_images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMizsldUzdF9"
      },
      "source": [
        "4 Implement a specific model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnfmr_mlciHC",
        "outputId": "8bdf2861-5171-4755-d075-cb7839ca4f0b"
      },
      "source": [
        "os.chdir(ROOT_DIR)\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "os.chdir('Mask_RCNN')\n",
        "!python setup.py -q install"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n",
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:672: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:672: UserWarning: Usage of dash-separated 'license-file' will not be supported in future versions. Please use the underscore name 'license_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:672: UserWarning: Usage of dash-separated 'requirements-file' will not be supported in future versions. Please use the underscore name 'requirements_file' instead\n",
            "  % (opt, underscore_opt))\n",
            "warning: the 'license_file' option is deprecated, use 'license_files' instead\n",
            "zip_safe flag not set; analyzing archive contents...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwpbVGys76Id"
      },
      "source": [
        "# Import Mask RCNN\n",
        "sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "train_dicom_dir = os.path.join(ROOT_DIR, 'stage_2_train_images')\n",
        "test_dicom_dir = os.path.join(ROOT_DIR, 'stage_2_test_images')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfNTTrlYziW2"
      },
      "source": [
        "5 Define some functions and classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg3NfwXNa7pc"
      },
      "source": [
        "def get_dicom_fps(dicom_dir):\n",
        "    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')\n",
        "    return list(set(dicom_fps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Crq9dMVimEB"
      },
      "source": [
        "def parse_dataset(dicom_dir, anns): \n",
        "    image_fps = get_dicom_fps(dicom_dir)\n",
        "    image_annotations = {fp: [] for fp in image_fps}\n",
        "    for index, row in anns.iterrows(): \n",
        "        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')\n",
        "        image_annotations[fp].append(row)\n",
        "    return image_fps, image_annotations "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuMQushlr8vu"
      },
      "source": [
        "The following parameters have been selected to reduce running time for demonstration purposes. \n",
        "\n",
        "These are not optimal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJg0f9zfrw4f"
      },
      "source": [
        "class DetectorConfig(Config):\n",
        "    \"\"\"\n",
        "    Configuration for training pneumonia detection on the RSNA pneumonia dataset. \n",
        "    Overrides values in the base Config class.\n",
        "    \"\"\"\n",
        "\n",
        "    # Give the configuration a recognizable name  \n",
        "    NAME = 'pneumonia'\n",
        "\n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 8 \n",
        "    BACKBONE = 'resnet50'\n",
        "    NUM_CLASSES = 2  # 1 background + 1 pneumonia classes\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "\n",
        "    IMAGE_MIN_DIM = 64\n",
        "    IMAGE_MAX_DIM = 64\n",
        "\n",
        "    RPN_ANCHOR_SCALES = (32, 64)\n",
        "    \n",
        "    TRAIN_ROIS_PER_IMAGE = 16\n",
        "    \n",
        "    MAX_GT_INSTANCES = 3\n",
        "    \n",
        "    DETECTION_MAX_INSTANCES = 3\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "    DETECTION_NMS_THRESHOLD = 0.1\n",
        "    \n",
        "    RPN_TRAIN_ANCHORS_PER_IMAGE = 16\n",
        "    STEPS_PER_EPOCH = 100 \n",
        "    TOP_DOWN_PYRAMID_SIZE = 32\n",
        "    STEPS_PER_EPOCH = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJrYavs8ufrV"
      },
      "source": [
        "config = DetectorConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD10hGr0urEC"
      },
      "source": [
        "class DetectorDataset(utils.Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
        "\n",
        "      super().__init__(self)\n",
        "\n",
        "      # Add classes\n",
        "      self.add_class('pneumonia', 1, 'Lung Opacity')\n",
        "\n",
        "      # add images \n",
        "      for i, fp in enumerate(image_fps):\n",
        "            annotations = image_annotations[fp]\n",
        "            self.add_image('pneumonia', image_id=i, path=fp, \n",
        "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
        "            \n",
        "      def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        return info['path']\n",
        "\n",
        "      def load_image(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        fp = info['path']\n",
        "        ds = pydicom.read_file(fp)\n",
        "        image = ds.pixel_array\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "            image = np.stack((image,) * 3, -1)\n",
        "        return image\n",
        "\n",
        "      def load_mask(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        annotations = info['annotations']\n",
        "        count = len(annotations)\n",
        "        if count == 0:\n",
        "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
        "            class_ids = np.zeros((1,), dtype=np.int32)\n",
        "        else:\n",
        "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
        "            class_ids = np.zeros((count,), dtype=np.int32)\n",
        "            for i, a in enumerate(annotations):\n",
        "                if a['Target'] == 1:\n",
        "                    x = int(a['x'])\n",
        "                    y = int(a['y'])\n",
        "                    w = int(a['width'])\n",
        "                    h = int(a['height'])\n",
        "                    mask_instance = mask[:, :, i].copy()\n",
        "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
        "                    mask[:, :, i] = mask_instance\n",
        "                    class_ids[i] = 1\n",
        "        return mask.astype(np.bool), class_ids.astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5jYe7GDyzYH"
      },
      "source": [
        "6 Examine the annotation data, parse the dataset, and view dicom image fields:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uijPByExkdQD"
      },
      "source": [
        "# training dataset\n",
        "anns = pd.read_csv(os.path.join(ROOT_DIR, ‘stage_2_train_labels.csv’))\n",
        "anns.head(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYaA4cN-kfXS"
      },
      "source": [
        "image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)\n",
        "ds = pydicom.read_file(image_fps[0]) # read dicom image from filepath \n",
        "image = ds.pixel_array # get image array\n",
        "# show dicom fields \n",
        "ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6_TUcUKy5C9"
      },
      "source": [
        "7 Split the data into training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OQMn3Znyjhh"
      },
      "source": [
        "# Original DICOM image size: 1024 x 1024\n",
        "ORIG_SIZE = 1024\n",
        "######################################################################\n",
        "# Modify this line to use more or fewer images for training/validation. \n",
        "# To use all images, do: image_fps_list = list(image_fps)\n",
        "image_fps_list = list(image_fps[:1000]) \n",
        "#####################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr_NaOhDyqrU"
      },
      "source": [
        "# split dataset into training vs. validation dataset \n",
        "# split ratio is set to 0.9 vs. 0.1 (train vs. validation, respectively)\n",
        "sorted(image_fps_list)\n",
        "random.seed(42)\n",
        "random.shuffle(image_fps_list)\n",
        "validation_split = 0.1\n",
        "split_index = int((1 - validation_split) * len(image_fps_list))\n",
        "image_fps_train = image_fps_list[:split_index]\n",
        "image_fps_val = image_fps_list[split_index:]\n",
        "print(len(image_fps_train), len(image_fps_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNj5KKuS08be"
      },
      "source": [
        "# prepare the training dataset using the DetectorDataset class\n",
        "dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
        "dataset_train.prepare()\n",
        "# prepare the validation dataset\n",
        "dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)\n",
        "dataset_val.prepare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LfyBi9L02Yp"
      },
      "source": [
        "8 Make some graphs to understand the data better:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJp6pRkI0zNB"
      },
      "source": [
        "# Show annotation(s) for a DICOM image \n",
        "test_fp = random.choice(image_fps_train)\n",
        "image_annotations[test_fp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKD643BP07Kc"
      },
      "source": [
        "# Load and display random samples and their bounding boxes\n",
        "# Suggestion: Run this a few times to see different examples.\n",
        "image_id = random.choice(dataset_train.image_ids)#choose a random image\n",
        "image_fp = dataset_train.image_reference(image_id)#image file path\n",
        "image = dataset_train.load_image(image_id)#load the chosen image\n",
        "mask, class_ids = dataset_train.load_mask(image_id)#load mask of the chosen img\n",
        "print(image.shape)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image[:, :, 0], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "masked = np.zeros(image.shape[:2])\n",
        "for i in range(mask.shape[2]):\n",
        "    masked += image[:, :, 0] * mask[:, :, i]\n",
        "plt.imshow(masked, cmap='gray')\n",
        "plt.axis('off')\n",
        "print(image_fp)\n",
        "print(class_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0UWjFBY4Yyz"
      },
      "source": [
        "9 Finetune some variables to custom values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW8-Dlqq4UOb"
      },
      "source": [
        "#finetuning some image augmentation variables to custom values\n",
        "augmentation = iaa.SomeOf((0, 1), [\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "        rotate=(-25, 25),\n",
        "        shear=(-8, 8)\n",
        "    ),\n",
        "    iaa.Multiply((0.9, 1.1))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiFBrVTG7lQ9"
      },
      "source": [
        "10 Train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRpetUh-7kjK"
      },
      "source": [
        "model = modellib.MaskRCNN(mode='training', config=config, model_dir=MODEL_DIR)\n",
        "NUM_EPOCHS = 1\n",
        "# Train Mask-RCNN Model \n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE, \n",
        "            epochs=NUM_EPOCHS, \n",
        "            layers='all',\n",
        "            augmentation=augmentation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ-4v57Q7yfn"
      },
      "source": [
        "11 Select trained model and make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V3PVjox75KO"
      },
      "source": [
        "# select trained model \n",
        "dir_names = next(os.walk(model.model_dir))[1]\n",
        "key = config.NAME.lower()\n",
        "dir_names = filter(lambda f: f.startswith(key), dir_names)\n",
        "dir_names = sorted(dir_names)\n",
        "\n",
        "if not dir_names:\n",
        "    import errno\n",
        "    raise FileNotFoundError(\n",
        "        errno.ENOENT,\n",
        "        \"Could not find model directory under {}\".format(self.model_dir))\n",
        "    \n",
        "fps = []\n",
        "# Pick last directory\n",
        "for d in dir_names: \n",
        "    dir_name = os.path.join(model.model_dir, d)\n",
        "    # Find the last checkpoint\n",
        "    checkpoints = next(os.walk(dir_name))[2]\n",
        "    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
        "    checkpoints = sorted(checkpoints)\n",
        "    if not checkpoints:\n",
        "        print('No weight files in {}'.format(dir_name))\n",
        "    else: \n",
        "      \n",
        "      checkpoint = os.path.join(dir_name, checkpoints[-1])\n",
        "      fps.append(checkpoint)\n",
        "      \n",
        "model_path = sorted(fps)[-1]\n",
        "print('Found model {}'.format(model_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9F17bAk8RJq"
      },
      "source": [
        "class InferenceConfig(DetectorConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I13KfIAN9STb"
      },
      "source": [
        "inference_config = InferenceConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKsVi7F08D28"
      },
      "source": [
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode='inference', \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Load trained weights (fill in path to trained weights here)\n",
        "assert model_path != \"\", \"Provide path to trained weights\"\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8zaXyiBGswI"
      },
      "source": [
        "# set color for class\n",
        "def get_colors_for_class_ids(class_ids):\n",
        "    colors = []\n",
        "    for class_id in class_ids:\n",
        "        if class_id == 1:\n",
        "            colors.append((.941, .204, .204))\n",
        "    return colors\n",
        "  \n",
        "# Show few example of ground truth vs. predictions on the validation dataset \n",
        "dataset = dataset_val\n",
        "fig = plt.figure(figsize=(10, 30))\n",
        "for i in range(4):\n",
        "  \n",
        "  image_id = random.choice(dataset.image_ids)\n",
        "  \n",
        "  original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_val, inference_config, \n",
        "                           image_id, use_mini_mask=False)\n",
        "        \n",
        "    plt.subplot(6, 2, 2*i + 1)\n",
        "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                                dataset.class_names,\n",
        "                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])\n",
        "    \n",
        "    plt.subplot(6, 2, 2*i + 2)\n",
        "    results = model.detect([original_image]) #, verbose=1)\n",
        "    r = results[0]\n",
        "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                                dataset.class_names, r['scores'], \n",
        "                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMRtOcWmG0Fq"
      },
      "source": [
        "12 Create the .csv submission file with predictions to be scored by Kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdBZWC3JG0_M"
      },
      "source": [
        "# Get filenames of test dataset DICOM images\n",
        "test_image_fps = get_dicom_fps(test_dicom_dir)\n",
        "# Make predictions on test images, write out sample submission \n",
        "def predict(image_fps, filepath='sample_submission.csv', min_conf=0.98): \n",
        "    \n",
        "    # assume square image\n",
        "    \n",
        "    with open(filepath, 'w') as file:\n",
        "      for image_id in tqdm(image_fps): \n",
        "        ds = pydicom.read_file(image_id)\n",
        "        image = ds.pixel_array\n",
        "          \n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
        "            image = np.stack((image,) * 3, -1) \n",
        "            \n",
        "        patient_id = os.path.splitext(os.path.basename(image_id))[0]\n",
        "results = model.detect([image])\n",
        "        r = results[0]\n",
        "out_str = \"\"\n",
        "        out_str += patient_id \n",
        "        assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n",
        "        if len(r['rois']) == 0: \n",
        "            pass\n",
        "        else: \n",
        "            num_instances = len(r['rois'])\n",
        "            out_str += \",\"\n",
        "            for i in range(num_instances): \n",
        "                if r['scores'][i] > min_conf: \n",
        "                    out_str += ' '\n",
        "                    out_str += str(round(r['scores'][i], 2))\n",
        "                    out_str += ' '\n",
        "# x1, y1, width, height \n",
        "                    x1 = r['rois'][i][1]\n",
        "                    y1 = r['rois'][i][0]\n",
        "                    width = r['rois'][i][3] - x1 \n",
        "                    height = r['rois'][i][2] - y1 \n",
        "                    bboxes_str = \"{} {} {} {}\".format(x1, y1, \\\n",
        "                                                  width, height)    \n",
        "                    out_str += bboxes_str\n",
        "file.write(out_str+\"\\n\")\n",
        "        \n",
        "# predict only the first 50 entries for testing\n",
        "sample_submission_fp = 'sample_submission.csv'\n",
        "predict(test_image_fps[:50], filepath=sample_submission_fp)\n",
        "output = pd.read_csv(sample_submission_fp, names=['id', 'pred_string'])\n",
        "output.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}